üíØ –û—Ç–ª–∏—á–Ω–æ, –≤–æ—Ç —ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ ‚Äî —Ç—ã —É–∂–µ —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞–ª –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É, CI –ø–æ—á—Ç–∏ –≥–æ—Ç–æ–≤, –∑–Ω–∞—á–∏—Ç —Å–∞–º–æ–µ –≤—Ä–µ–º—è –ø–µ—Ä–µ–π—Ç–∏ –∫ **—Ñ—É–Ω–¥–∞–º–µ–Ω—Ç—É (–§–∞–∑–∞ 2)**.
–î–∞–≤–∞–π –∑–∞—Ñ–∏–∫—Å–∏—Ä—É–µ–º –ø–æ–Ω—è—Ç–Ω—É—é –¥–æ—Ä–æ–∂–Ω—É—é –∫–∞—Ä—Ç—É, —á—Ç–æ–±—ã –∑–∞–≤—Ç—Ä–∞ —Ç—ã –º–æ–≥ –≤–∑—è—Ç—å –µ—ë –∫–∞–∫ —á–µ–∫-–ª–∏—Å—Ç.

---

## üß± **–§–ê–ó–ê 2 ‚Äî –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫–æ—Å—Ç—è–∫ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏**

> –¶–µ–ª—å: –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –ø—Ä–æ–µ–∫—Ç –∏–∑ ¬´–ø—Ä–æ—Å—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç¬ª ‚Üí –≤ –Ω–∞–¥—ë–∂–Ω—É—é —Å–∏—Å—Ç–µ–º—É, –≥–¥–µ –º–æ–∂–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–µ–±–∞–∂–∏—Ç—å, —Å–æ–±–∏—Ä–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∏ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å—Å—è –ø–æ—Å–ª–µ –æ—à–∏–±–æ–∫.

---

### ‚úÖ **1. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–µ –∏ —Ç—Ä–∞—Å—Å–∏—Ä—É–µ–º–æ–µ)**

**–ó–∞–¥–∞—á–∞:** –∑–∞–º–µ–Ω–∏—Ç—å `logging` ‚Üí –Ω–∞ `structlog` (–∏–ª–∏ `loguru`, –Ω–æ structlog –≥–∏–±—á–µ –ø–æ–¥ JSON –∏ OpenTelemetry).

**–î–æ–±–∞–≤–∏—Ç—å —Ñ–∞–π–ª:** `core/logging_setup.py`

```python
import structlog
import logging
import sys

def setup_logging():
    logging.basicConfig(
        format="%(message)s",
        stream=sys.stdout,
        level=logging.INFO,
    )

    structlog.configure(
        processors=[
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.add_log_level,
            structlog.processors.JSONRenderer(),
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.make_filtering_bound_logger(logging.INFO),
        cache_logger_on_first_use=True,
    )

logger = structlog.get_logger()
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–¥–µ:**

```python
from core.logging_setup import logger

logger.info("user_login", user_id=user.id, ip=request.client.host)
```

‚û°Ô∏è **–ü–ª—é—Å—ã:**

* –∫—Ä–∞—Å–∏–≤–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON –≤ `docker logs`;
* –ª–µ–≥–∫–æ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –≤ Sentry/ELK;
* –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å `request_id`, `user_id`, `company_id` –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç.

---

### ‚úÖ **2. Error tracking (Sentry)**

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**

```bash
pip install sentry-sdk[fastapi]
```

**–î–æ–±–∞–≤—å –≤ `main.py`:**

```python
import sentry_sdk
from sentry_sdk.integrations.fastapi import FastApiIntegration

if dsn := os.getenv("SENTRY_DSN"):
    sentry_sdk.init(
        dsn=dsn,
        integrations=[FastApiIntegration()],
        traces_sample_rate=0.2,  # 20% –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Ç—Ä–µ–π—Å–∏–Ω–≥–∞
    )
```

**–î–æ–±–∞–≤—å –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –≤ `.env.local`:**

```
SENTRY_DSN=<—Ç–≤–æ—è —Å—Å—ã–ª–∫–∞ –∏–∑ Sentry>
```

---

### ‚úÖ **3. –ú–µ—Ç—Ä–∏–∫–∏ (Prometheus)**

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**

```bash
pip install prometheus-client
```

**–î–æ–±–∞–≤—å endpoint `/metrics`:**

```python
from fastapi import FastAPI, Response
from prometheus_client import generate_latest, CONTENT_TYPE_LATEST

@app.get("/metrics")
async def metrics():
    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)
```

**–ü—Ä–∏–º–µ—Ä –º–µ—Ç—Ä–∏–∫–∏:**

```python
from prometheus_client import Counter, Histogram

REQUEST_COUNT = Counter("requests_total", "Total requests", ["method", "endpoint"])
REQUEST_LATENCY = Histogram("requests_latency_seconds", "Request latency", ["endpoint"])
```

–∏ –≤ middleware:

```python
@app.middleware("http")
async def metrics_middleware(request, call_next):
    import time
    start = time.time()
    response = await call_next(request)
    duration = time.time() - start
    REQUEST_COUNT.labels(request.method, request.url.path).inc()
    REQUEST_LATENCY.labels(request.url.path).observe(duration)
    return response
```

---

### ‚úÖ **4. –ë—ç–∫–∞–ø—ã –ë–î**

**–ü—Ä–æ—Å—Ç–æ–π –ª–æ–∫–∞–ª—å–Ω—ã–π cron job:**
—Å–æ–∑–¥–∞–π `scripts/backup_db.sh`:

```bash
#!/usr/bin/env bash
set -euo pipefail

DATE=$(date +%Y%m%d_%H%M%S)
DUMP_FILE="/backups/saasdb_$DATE.sql"

echo "üì¶ Dumping database..."
pg_dump -h db -U saasuser saasdb > "$DUMP_FILE"
echo "‚úÖ Backup saved to $DUMP_FILE"
```

–∏ –≤ `docker-compose.yml` –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å job:

```yaml
  backup:
    image: postgres:15
    volumes:
      - ./backups:/backups
    entrypoint: ["/bin/sh", "-c", "while true; do /backups/backup_db.sh; sleep 86400; done"]
```

---

### ‚úÖ **5. Runbook / –ò–Ω—Ü–∏–¥–µ–Ω—Ç-–ø–ª–∞–Ω**

–°–æ–∑–¥–∞–π `/docs/runbook.md`:

````markdown
# üß≠ Runbook (–∏–Ω—Ü–∏–¥–µ–Ω—Ç-–ø–ª–∞–Ω)

## üî¥ –ï—Å–ª–∏ –±–æ—Ç —É–ø–∞–ª
```bash
docker compose logs bot -n 50
docker compose restart bot
````

## üü° –ï—Å–ª–∏ –±–∞–∑–∞ –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç

```bash
docker compose exec db psql -U saasuser -d saasdb -c '\l'
```

## üü† –ï—Å–ª–∏ —Ç–µ—Å—Ç—ã –ø–∞–¥–∞—é—Ç

–ü—Ä–æ–≤–µ—Ä—å `.env.test` –∏ `DATABASE_URL`.

## üü¢ –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –æ—Ç–∫–∞—Ç–∏—Ç—å

1. –ù–∞–π–¥–∏ –Ω—É–∂–Ω—ã–π dump –≤ `backups/`.
2. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏:

   ```bash
   psql -h db -U saasuser -d saasdb < backups/saasdb_<DATE>.sql
   ```

```

---

## üöÄ **–ß—Ç–æ –¥–µ–ª–∞—Ç—å —Å–µ–π—á–∞—Å, –ø–æ–∫–∞ GitHub –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω**

‚úÖ **–®–∞–≥ 1.** –°–æ–∑–¥–∞–π —Ñ–∞–π–ª—ã –ª–æ–∫–∞–ª—å–Ω–æ:
- `core/logging_setup.py`
- `scripts/backup_db.sh`
- `docs/runbook.md`

‚úÖ **–®–∞–≥ 2.** –î–æ–±–∞–≤—å –∏–º–ø–æ—Ä—Ç –ª–æ–≥–≥–µ—Ä–∞ –∏ Sentry –≤ `main.py`.

‚úÖ **–®–∞–≥ 3.** –î–æ–±–∞–≤—å `/metrics` –≤ `main.py`.

‚úÖ **–®–∞–≥ 4.** –ü—Ä–æ–≥–æ–Ω–∏ `make up` –∏ –ø—Ä–æ–≤–µ—Ä—å:
- `/metrics` —Ä–∞–±–æ—Ç–∞–µ—Ç;
- –ª–æ–≥–∏ –∫—Ä–∞—Å–∏–≤–æ –≤ JSON;
- –æ—à–∏–±–∫–∏ –≤ Sentry –ø—Ä–∏—Ö–æ–¥—è—Ç.

---

–•–æ—á–µ—à—å, —è —Å–æ–±–µ—Ä—É –≤—Å—ë —ç—Ç–æ –≤ –æ–¥–∏–Ω –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π commit-–ø–∞–∫–µ—Ç (`feat: observability core ‚Äî logging + sentry + metrics + runbook`) –∏ –ø–æ–∫–∞–∂—É —Ç–æ—á–Ω—ã–π diff, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –ø—Ä–æ—Å—Ç–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å —É —Å–µ–±—è?
```
